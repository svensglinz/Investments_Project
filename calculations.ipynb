{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "The following script has 4 main sections.<br>\n", "We first calculate the optimal investment weights of a trading strategy<br>\n", "by optimization. Then, we calculate the in and out of sample returns<br>\n", "for the strategy and the chosen benchmark.<br>\n", "Ultimately, we calculate performance and risk ratios and plot portfolio<br>\n", "characteristics of the investment strategy in comparison to the benchmark.<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["oad libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import yfinance as yf\n", "import pandas as pd\n", "import numpy as np\n", "import math as m\n", "import matplotlib.pyplot as plt\n", "import matplotlib.ticker as mtick\n", "import matplotlib.dates as mdates\n", "from scipy.optimize import minimize\n", "from scipy.optimize import Bounds\n", "import datetime as dt\n", "from sklearn.linear_model import LinearRegression\n", "import dataframe_image as dfi"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "                                                                          #<br>\n", "                               #SECTION 1                                 #<br>\n", "      Define key parameters, import needed files and define investment   #<br>\n", "      universe of stocks which the strategy invests in                    #<br>\n", "                                                                          #<br>\n", "###########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine parameters of investment period start"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_backtesting = np.datetime64(\"2011-01-01\")\n", "end_backtesting = np.datetime64(\"2021-12-31\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["mport needed CSV files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks_index = pd.read_csv(\"files/index_constituents_data.csv\", index_col= 0)\n", "benchmark = pd.read_csv(\"files/benchmark.csv\", index_col= 0)\n", "Gross_Price = pd.read_csv(\"files/Gross_Prices_EUR.csv\", index_col= 0)\n", "Net_Price = pd.read_csv(\"files/Net_Prices_EUR.csv\", index_col= 0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ormat index to date"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Gross_Price.index = pd.to_datetime(Gross_Price.index)\n", "Net_Price.index = pd.to_datetime(Net_Price.index)\n", "benchmark.index = pd.to_datetime(benchmark.index)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Select stocks which the strategy invests in<br>\n", "our strategy goes long in the top 10 highest dividend stocks and short in the<br>\n", "top 10 lowest dividend stocks --> We select these stocks as our investmnet stocks<br>\n", "drop BHP stock for which dividends have not been calculated correctly!<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks_index = stocks_index.sort_values(by = \"Yield\", ascending= False)\n", "stocks_index = stocks_index.drop(\"BHP.L\")\n", "stocks_invest = stocks_index.iloc[np.r_[0:10, 39:49]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["elect prices of stocks which we invest in"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Gross_Price_selected = Gross_Price[stocks_invest.index]\n", "Net_Price_selected = Net_Price[stocks_invest.index]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "                                                                          #<br>\n", "                               #SECTION 2                                 #<br>\n", "    Calculate Optimal Strategy stock weights with various constraints     #<br>\n", "                      and visualize optimization                          #<br>\n", "                                                                          #<br>\n", "###########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["stimate expected returns and var-cov matrix for optimization (with in sample data!)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ER = Gross_Price_selected[Gross_Price_selected.index < end_backtesting].pct_change().mean()\n", "S = Gross_Price_selected[Gross_Price_selected.index < end_backtesting].pct_change().cov()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine functions for optimization (variance, return,  negative sharp ratio)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pvar(w, S):\n", "    return (w.T @ S @ w)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pret(w, ER):\n", "    return (w.T @ ER)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sharpe(w ,ER, S):\n", "    return -(w.T @ ER)/ ((w.T @ S @ w) ** 0.5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["---------------------------------------------------------------------------<br>\n", "Calculate Optimized Portfolio<br>\n", "---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N = len(ER)\n", "x0 = np.ones(N)/N"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "#set up constraints<br>\n", "first constraint -> total investment = 100% long<br>\n", "second constraint- > Values smaller than - min_weight (shocks which are shorted)<br>\n", "third constraint -> Values larger than min_weight (stock which are longed)<br>\n", "bounds = maximum long and short % for stocks<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["min_weight = 0.02"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cons_multiple = ({\"type\": \"eq\", \"fun\" : lambda x: np.sum(x) - 1},\n", "                {\"type\": \"ineq\", \"fun\" : lambda x: -min_weight -x[10:20]},\n", "                {\"type\": \"ineq\", \"fun\" : lambda x: x[0:10]- min_weight})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bounds = Bounds(-0.2, 0.2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["nly constraint for unconstrained portfolio --> Total stock weights == 100%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cons_simple = ({\"type\": \"eq\", \"fun\" : lambda x: np.sum(x) - 1})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate optimized values (GMVP and MSRP constrained and unconstrained)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["GMVP_const = minimize(pvar, x0, method='SLSQP', args=S, constraints = cons_multiple,\n", "                      options={'disp': True, 'ftol': 1e-9}, bounds = bounds)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["GMVP_unconst = minimize(pvar, x0, method = \"SLSQP\", args = S,constraints = cons_simple,\n", "                        options={'disp': True, 'ftol': 1e-9})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MSRP_const = minimize(sharpe, x0, method='SLSQP', args=(ER, S), constraints=cons_multiple,\n", "                      options={'disp': True, 'ftol': 1e-9}, bounds = bounds)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MSRP_unconst = minimize(sharpe, x0, method='SLSQP', args=(ER,S), constraints = cons_simple,\n", "                        options={'disp': True, 'ftol': 1e-9})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["omplete data set of selected stocks with calculated constrained MSRP values & export for presentation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks_invest[\"weights\"] = MSRP_const.x\n", "stocks_invest[\"weights_unconst\"] = MSRP_unconst.x\n", "dfi.export(stocks_invest, \"plots/selected_portfolio_characteristics.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                  #Visualize efficient Frontier\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Generate efficient frontier plot by doing the following: <br>\n", "1. Minimize the negative value of the expected portfolio return <br>\n", "given a deterministic variance and the same rules as above (eg. min 2% in each stock)<br>\n", "as restrictions in the optimization. --> We thus retrieve the maximum return given <br>\n", "all restrictions for a given variance. <br>\n", "2. We construct \"random portfolios\" which fulfill all the restrictions by minimizing a function<br>\n", "which consists of a random array and a modulus operation which should randomize the optimization <br>\n", "results. We can then calculate the expected return and variance of these portfolios and add them <br>\n", "to the plot.<br>\n", "<br>\n", "alculate volatility and expected return of GMVP and MSRP constrained for plotting further below"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["GMVP_const_ER = pret(w = GMVP_const.x, ER = ER) * 250\n", "GMVP_const_VAR = m.sqrt(pvar(w = GMVP_const.x, S = S) * 250)\n", "MSRP_const_ER =  pret(w = MSRP_const.x, ER = ER) * 250\n", "MSRP_const_VAR = m.sqrt(pvar(w = MSRP_const.x, S = S) * 250)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine negative portfolio return function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pret_sim(w, ER):\n", "    return (-(w.T @ ER))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ariances to loop over"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["var_list = np.arange(0.1, 0.6, 0.01)\n", "bounds = Bounds(-0.2, 0.2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["nitialize lists to store results in"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MVF_var_const = []\n", "MVF_ret_const = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["oop over variances and maximize expected return given that portfolio variance = given variance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in var_list:\n", "    max_var = i\n", "    cons = ({\"type\": \"eq\", \"fun\" : lambda x: np.sum(x) - 1},\n", "            {\"type\": \"eq\", \"fun\" : lambda x: m.sqrt((x.T @ S @ x)* 250) - max_var},\n", "            {\"type\": \"ineq\", \"fun\": lambda x: -min_weight - x[10:20]},\n", "            {\"type\": \"ineq\", \"fun\": lambda x: x[0:10] - min_weight})\n", "    maximized = minimize(pret_sim, x0, method='SLSQP', args= ER,\n", "                         options={'disp': True, 'ftol': 1e-9},\n", "                         constraints=cons, bounds = bounds)\n\n", "    #only store result if optimization was successful!\n", "    if maximized.success:\n", "        MVF_var_const.append(i)\n", "        MVF_ret_const.append(maximized.fun * -250)\n", "    else:\n", "        continue"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                  #Visualize efficient Frontier\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["random_portfolio = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["random\" function which when optimized gives \"random\" portfolios"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def rand_funct(x,y):\n", "    return ((x % y)/y).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["eight constraints of individual stocks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cons = ({\"type\": \"eq\", \"fun\" : lambda x: np.sum(x) - 1},\n", "        {\"type\": \"ineq\", \"fun\": lambda x: -min_weight - x[10:20]},\n", "        {\"type\": \"ineq\", \"fun\": lambda x: x[0:10] - min_weight})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["imulate 100 different portfolios which fulfill the constraints"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["i = 0\n", "while i < 100:\n", "    y = np.random.uniform(low= 0, high=1, size=N)\n", "    MSRP_sim = minimize(rand_funct, x0, method='SLSQP', args= y,\n", "                        constraints=cons, options={'disp': True, 'ftol': 1e-9},\n", "                        bounds = bounds)\n", "    i = i + 1\n\n", "    #only store successful optimizations\n", "    if MSRP_sim.success:\n", "        random_portfolio.append(MSRP_sim.x)\n", "    else:\n", "        continue"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MVF_randvar_const = []\n", "MVF_randret_const = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate return and variance (yearly) from calculated \"random\" portfolios"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(len(random_portfolio)):\n", "    exp_return = pret(w = random_portfolio[i], ER = ER)\n", "    exp_var = pvar(w = random_portfolio[i], S = S)\n", "    exp_return_year = exp_return * 250\n", "    exp_var_year = m.sqrt(exp_var * 250)\n", "    MVF_randvar_const.append(exp_var_year)\n", "    MVF_randret_const.append(exp_return_year)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MVF_var_const.insert(0, GMVP_const_VAR)\n", "MVF_ret_const.insert(0, GMVP_const_ER)\n", "CAL_x = np.linspace(0, MSRP_const_VAR + 0.2, 50, endpoint=True)\n", "SR_MSRP = MSRP_const_ER / MSRP_const_VAR\n", "CAL_y = 0 + SR_MSRP*CAL_x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["frontier_points = pd.DataFrame({\"variance\": MVF_var_const, \"return\": MVF_ret_const})\n", "max_ret_index = frontier_points[\"return\"].idxmax()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize = (15,10))\n", "plt.plot(frontier_points.variance.iloc[0:max_ret_index + 1], frontier_points[\"return\"].iloc[0:max_ret_index + 1])\n", "plt.plot(frontier_points.variance.iloc[max_ret_index: len(frontier_points)],\n", "         frontier_points[\"return\"].iloc[max_ret_index: len(frontier_points)], color = \"grey\", ls =  \"--\")\n", "plt.scatter(MVF_randvar_const, MVF_randret_const)\n", "plt.scatter(GMVP_const_VAR, GMVP_const_ER, s = 70)\n", "plt.scatter(MSRP_const_VAR, MSRP_const_ER, s = 70)\n", "plt.plot(CAL_x, CAL_y)\n", "plt.xlim([0,0.4])\n", "plt.ylim([0,0.4])\n", "plt.title(\"Minimum Variance Frontier Simulated\", size = 25)\n", "plt.xlabel(\"Volatility\", size = 15)\n", "plt.ylabel(\"Return\", size = 15)\n", "plt.legend([\"Minimum Variance Frontier\", \"?\", \"Capital Allocation Line\",\"random portfolios\", \"GMVP\", \"MSRP\"],\n", "           prop={'size': 10})\n", "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.xticks(size = 15)\n", "plt.yticks(size = 15)\n", "plt.savefig(\"minimumvariancefrontier.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "                                                                          #<br>\n", "                               #SECTION 2                                 #<br>\n", "                          Calculate  returns of                           #<br>\n", "                strategy and benchmark in and out of sample               #<br>\n", "                                                                          #<br>\n", "###########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["unction which calculates the indexed performance (start = 1) of various stocks and start investment weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def indexed_performance(start, prices, weights, end = None):\n\n", "    #filter desired time range\n", "    if end is None:\n", "        temp = prices[prices.index >= start]\n", "    else:\n", "        temp = prices[(prices.index >= start) & (prices.index < end)]\n\n", "    #define daily percentage changes + 1\n", "    temp = temp.pct_change() + 1\n\n", "    #replace first row with weights of each stock --> Initial Investment = 1\n", "    temp.iloc[0] = weights\n\n", "    #take cumulative return of each stock * initial investment (weight) and sum up horizontaly\n", "    temp = temp.cumprod().sum(axis = 1)\n", "    return(temp)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate weights of short stocks / long stocks  that they sum up to 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["weights_short = stocks_invest.weights[stocks_invest.weights < 0] / stocks_invest.weights[stocks_invest.weights < 0].sum()\n", "weights_long =  stocks_invest.weights[stocks_invest.weights > 0] / stocks_invest.weights[stocks_invest.weights > 0].sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate needed indexed performance series"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample_net = indexed_performance(start = start_backtesting, end = end_backtesting,\n", "                                    weights = MSRP_const.x, prices = Net_Price_selected)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample_gross = indexed_performance(start = start_backtesting, end = end_backtesting,\n", "                                    weights = MSRP_const.x, prices = Gross_Price_selected)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_gross_short = indexed_performance(start = end_backtesting, weights = weights_short,\n", "                                             prices = Gross_Price_selected[stocks_invest[stocks_invest.weights < 0].index])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_gross_long = indexed_performance(start = end_backtesting, weights = weights_long,\n", "                                            prices = Gross_Price_selected[stocks_invest[stocks_invest.weights > 0].index])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_gross = indexed_performance(start = end_backtesting, weights = MSRP_const.x,\n", "                                       prices = Gross_Price_selected)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ombine all returns to data frame (one for in and one for out of sample performance)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample = pd.DataFrame({\"strategy_net\": in_sample_net,\n", "                          \"strategy_gross\": in_sample_gross},\n", "                         index = in_sample_net.index)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample = pd.DataFrame({\"strategy_gross\": out_sample_gross,\n", "                           \"long_gross\": out_sample_gross_long,\n", "                           \"short_gross\": out_sample_gross_short},\n", "                           index = out_sample_gross.index)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["oin benchmark data & calculate indexed performance of benchmark"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample = in_sample.join(benchmark)\n", "out_sample = out_sample.join(benchmark)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample[[\"benchmark_gross\", \"benchmark_net\"]] = in_sample[[\"benchmark_gross\", \"benchmark_net\"]].div(in_sample[[\"benchmark_gross\", \"benchmark_net\"]].head(1).iloc[0])\n", "out_sample[[\"benchmark_gross\", \"benchmark_net\"]] = out_sample[[\"benchmark_gross\", \"benchmark_net\"]].div(out_sample[[\"benchmark_gross\", \"benchmark_net\"]].head(1).iloc[0])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ave in and out of sample returns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample.to_csv(\"files/in_sample.csv\")\n", "out_sample.to_csv(\"files/out_sample.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "                                                                          #<br>\n", "                           #SECTION 3                                     #<br>\n", "       #Calculate in and out of sample risk & performance ratios          #<br>\n", "                                                                          #<br>\n", "###########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                        #Percent Formatting\n", "#---------------------------------------------------------------------------\n", "#Function that returns a float number rounded to n digits and returns\n", "#it as a string with \"%\" in the end (ie. in: 0.467, out: 46.7%)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def to_pct(x, digits):\n", "    out = str(round(x * 100, digits)) + \"%\"\n", "    return out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                        #Annualized Sharp Ratio\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ays = days per year (assumed 250 here)<br>\n", "f_rate = annualized risk free rate<br>\n", "rices for which ratio should be alculated"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sharp_ratio(price, days, rf_rate):\n", "    ER = price.pct_change().mean()\n", "    SD = price.pct_change().std()\n", "    SR = (ER-rf_rate/days)/SD * m.sqrt(days)\n", "    return round(SR,2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                        #Yearly volatility\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def yearly_vol(price, days, pct = True):\n", "    vol = m.sqrt(price.pct_change().var() * days)\n", "    if pct:\n", "        return to_pct(vol, 2)\n", "    else:\n", "        return vol"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                        #alpha and beta\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["eriod = period of returns for which regression should be run (eg. \"1Y\", \"1M\", \"1d\")<br>\n", "wargs = optional where only alpha, beta, x or y can be returned form function (param!)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def alpha_beta(strategy, benchmark, period, pct = True, **kwargs):\n", "    daily_ret_strategy = strategy.pct_change().fillna(0) + 1\n", "    daily_ret_BM = benchmark.pct_change().fillna(0) + 1\n", "    period_ret_strategy = daily_ret_strategy.groupby(pd.Grouper(freq=period)).prod() - 1\n", "    period_ret_BM = daily_ret_BM.groupby(pd.Grouper(freq=period)).prod() -1\n", "    model = LinearRegression().fit(period_ret_BM.to_numpy().reshape((-1,1)),\n", "                                    period_ret_strategy.to_numpy().reshape((-1,1)))\n", "    beta = model.coef_[0][0]\n", "    if pct:\n", "        alpha = to_pct(model.intercept_[0],2)\n", "    else:\n", "        alpha = model.intercept_[0]\n", "    results = {\"alpha\": alpha,\n", "               \"beta\": beta,\n", "               \"x\": period_ret_BM.to_list(),\n", "               \"y\": period_ret_strategy.to_list()}\n", "    if len(kwargs) == 0:\n", "        return(results)\n", "    else:\n", "        return(results.get(kwargs.get(\"param\")))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                        #Maximum Drawdown\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def maxdd(price, pct = True):\n", "    maxdd = price.diff().cumsum().min()\n", "    if pct:\n", "        return to_pct(maxdd, 2)\n", "    else:\n", "        return maxdd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                        #N Day unfiltered 99% VAR\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": [" as number of days (integer)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def NDAYVar(price, N, pct = True):\n", "    daily_ret = price.pct_change().fillna(0) + 1\n", "    daily_ret = daily_ret.reset_index(drop = True)\n", "    nday_ret = daily_ret.groupby(daily_ret.index // N).prod() - 1\n", "    VAR = nday_ret.quantile(0.01)\n", "    if pct:\n", "        return to_pct(np.abs(VAR), 2)\n", "    else:\n", "        return np.abs(VAR)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                #Expected N day return or total Return\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def nday_ret(price, N = None, TR = False, pct = True):\n", "    if TR:\n", "        ret = price.tail(1)[0] / price.head(1)[0] -1\n", "    else:\n", "        ret = price.pct_change().mean() * N\n", "    if pct:\n", "        return to_pct(ret, 2)\n", "    else:\n", "        return ret"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine return series for which ratios should be calculated:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["BM_in = in_sample[\"benchmark_gross\"]\n", "BM_out = out_sample[\"benchmark_gross\"]\n", "strategy_in = in_sample[\"strategy_gross\"]\n", "strategy_out = out_sample[\"strategy_gross\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ssemble dicts with risk return metrics"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_BM_in = {\"Avg. Yearly Return\": nday_ret(BM_in, N = 250),\n", "         \"Avg. Yearly Sharp Ratio\": sharp_ratio(BM_in, days = 250, rf_rate = 0),\n", "         \"Max. Drawdown\": maxdd(BM_in, \"5d\"),\n", "         \"Alpha (monthly Returns)\": \"0%\",\n", "         \"Beta (monthly Returns)\": 1,\n", "         \"Avg. Ann. Vol\": yearly_vol(BM_in, days = 250),\n", "         \"5d 99% VAR\": NDAYVar(BM_in, N = 5)}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_BM_out = {\"Return YTD\": nday_ret(BM_out, TR = True),\n", "         \"Avg. Yearly Sharp Ratio\": sharp_ratio(BM_out, days = 250, rf_rate = 0),\n", "         \"Max. Drawdown\": maxdd(BM_out, \"5d\"),\n", "         \"Alpha (weekly Returns)\": \"0%\",\n", "         \"Beta (weekly Returns)\": 1,\n", "         \"Avg. Ann. Vol\": yearly_vol(BM_out, days = 250),\n", "         \"5d 99% VAR\": NDAYVar(BM_out, N = 5)}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_strategy_in = {\"Avg. Yearly Return\": nday_ret(strategy_in, N = 250),\n", "               \"Avg. Yearly Sharp Ratio\": sharp_ratio(strategy_in, days = 250, rf_rate = 0),\n", "               \"Max. Drawdown\": maxdd(strategy_in, \"5d\"),\n", "               \"Alpha (monthly Returns)\": alpha_beta(strategy_in, BM_in, \"1M\", param = \"alpha\"),\n", "               \"Beta (monthly Returns)\": round(alpha_beta(strategy_in, BM_in, \"1M\", param = \"beta\"),2),\n", "               \"Avg. Ann. Vol\": yearly_vol(strategy_in, days = 250),\n", "               \"5d 99% VAR\": NDAYVar(strategy_in, N = 5)}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_strategy_out = {\"Return YTD\": nday_ret(strategy_out, TR = True),\n", "                \"Avg. Yearly Sharp Ratio\": sharp_ratio(strategy_out, days = 250, rf_rate = 0),\n", "                \"Max. Drawdown\": maxdd(strategy_out, \"5d\"),\n", "                \"Alpha (weekly Returns)\": alpha_beta(strategy_out, BM_out, \"1W\", param = \"alpha\"),\n", "                \"Beta (weekly Returns)\": round(alpha_beta(strategy_out, BM_out, \"1W\", param = \"beta\"),2),\n", "                \"Avg. Ann. Vol\": yearly_vol(strategy_out, days = 250),\n", "                \"5d 99% VAR\": NDAYVar(strategy_out, N = 5)}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["risk_factors_out = pd.DataFrame({\"Benchmark\": ratios_BM_in, \"Strategy\": ratios_strategy_in})\n", "risk_factors_in = pd.DataFrame({\"Benchmark\": ratios_BM_out, \"Strategy\": ratios_strategy_out})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfi.export(risk_factors_out, \"plots/risk_factors_out.png\")\n", "dfi.export(risk_factors_in, \"plots/risk_factors_in.png\")\n", "#---------------------------------------------------------------------------\n", "        #Plot Visual Example for in Sample Alpha/ Beta Calculation\n", "#---------------------------------------------------------------------------\n", "#plot regression line"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["params = alpha_beta(strategy_in, BM_in, period = \"1M\", pct = False)\n", "x = np.arange(min(params.get(\"x\"))-0.1, max(params.get(\"x\"))+0.1, 0.01)\n", "fitted_y = params.get(\"alpha\") + params.get(\"beta\") * x"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ssemble plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig, ax = plt.subplots(figsize = (15,10))\n", "plt.scatter(params.get(\"x\"), params.get(\"y\"))\n", "plt.plot(x, fitted_y)\n", "plt.plot(x, x)\n", "plt.title(\"Monthly Returns Strategy vs. Benchmark (in sample)\", size = 25)\n", "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.ylabel(\"Monthly Returns Strategy\", size = 15)\n", "plt.xlabel(\"Monthly Returns Benchmark\", size = 15)\n", "plt.axhline(0, color = \"black\", ls = \"--\", lw = 1)\n", "plt.axvline(0, color = \"black\", ls =  \"--\", lw = 1)\n", "plt.xticks(size = 15)\n", "plt.yticks(size = 15)\n", "plt.legend([\"liner fit\", \"x = y\"], prop = {\"size\": 15})\n", "plt.savefig(\"plots/in_sample_alphabetaplot.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "                                                                          #<br>\n", "                           #SECTION 4                                     #<br>\n", "       #Calculate and plot portfolio characteristics vs. Benchmark        #<br>\n", "                                                                          #<br>\n", "###########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["            #Excess Return Strategy vs. Benchmark Plot\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate return over out of sample period for all stocks in the benchmark index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_all = Gross_Price[Gross_Price.index > end_backtesting]\n", "out_sample_all = out_sample_all.pct_change() + 1\n", "out_sample_all = out_sample_all.fillna(1).cumprod()\n", "out_return_all = out_sample_all.iloc[len(out_sample_all.index)-1].div(out_sample_all.iloc[0]) - 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate excess return contribution as (Weight Strategy - Weigh Index) * Return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ret_contrib = stocks_index.join(stocks_invest[\"weights\"]).fillna(0)\n", "ret_contrib = ret_contrib[[\"Name\", \"weights\", \"index_weights\"]]\n", "ret_contrib[\"diff_weights\"] = ret_contrib[\"weights\"] - ret_contrib[\"index_weights\"]\n", "ret_contrib = ret_contrib.join(pd.DataFrame(out_return_all))\n", "ret_contrib = ret_contrib.rename(columns = {0: \"return\"})\n", "ret_contrib[\"diff_return\"] = ret_contrib[\"diff_weights\"] * ret_contrib[\"return\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot and save results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 10))\n", "ax = fig.add_subplot(1,1,1)\n", "plt.bar(ret_contrib.Name[0:10], ret_contrib.diff_return[0:10])\n", "plt.bar(ret_contrib.Name[10:39], ret_contrib.diff_return[10:39])\n", "plt.bar(ret_contrib.Name[39:49], ret_contrib.diff_return[39:49])\n", "plt.legend([\"Long\", \"Not Invested\", \"Short\", \"Currencies\"])\n", "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.title(\"Decomposition of out of Sample excess Returns\", size = 22)\n", "plt.ylabel(\"Excess Return Strategy vs. Benchmark\", size = 15)\n", "plt.subplots_adjust(bottom = 0.3)\n", "plt.xticks(rotation=90)\n", "plt.yticks(size = 12)\n", "plt.savefig(\"plots/excess_return_breakdown.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #Out of Sample Gross Strategy vs Benchmark Performance\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 10))\n", "plt.plot(out_sample[[\"strategy_gross\", \"benchmark_gross\"]])\n", "plt.legend(out_sample[[\"strategy_gross\", \"benchmark_gross\"]].columns,\n", "           prop = {\"size\": 15})\n", "plt.title(\"Out of Sample Strategy Performance (TR)\", size = 20)\n", "plt.ylabel(\"Cumulative Return\", size = 15)\n", "plt.yticks(size = 15)\n", "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n", "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n", "plt.xticks(size = 15)\n", "plt.savefig(\"plots/outofsample_performance.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        #In Sample Gross Strategy vs Benchmark Performance\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 10))\n", "plt.plot(in_sample[[\"strategy_gross\", \"benchmark_gross\"]])\n", "plt.legend(in_sample[[\"strategy_gross\", \"benchmark_gross\"]].columns,\n", "           prop = {\"size\": 15})\n", "plt.title(\"In Sample Strategy Performance\", size = 22)\n", "plt.ylabel(\"Cumulative Return\")\n", "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n", "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n", "plt.xticks(size = 13)\n", "plt.yticks(size = 13)\n", "plt.savefig(\"plots/insample_performance.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                  #In Sample Performance Net vs. Gross\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 10))\n", "plt.plot(in_sample[[\"strategy_gross\", \"strategy_net\", \"benchmark_gross\", \"benchmark_net\"]])\n", "plt.legend(in_sample[[\"strategy_gross\", \"strategy_net\", \"benchmark_gross\", \"benchmark_net\"]].columns,\n", "           prop = {\"size\": 15})\n", "plt.title(\"In Sample Strategy Performance (net and gross) Comparison\", size = 22)\n", "plt.ylabel(\"Cumulative Return\", size = 15)\n", "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n", "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n", "plt.xticks(size = 13)\n", "plt.yticks(size = 13)\n", "plt.savefig(\"plots/insample_performance_netgross.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["     #Out of Sample Performance Decomposition Long/ Short Portfolio\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 10))\n", "plt.plot(out_sample[[\"strategy_gross\", \"benchmark_gross\", \"long_gross\", \"short_gross\"]])\n", "plt.legend(out_sample[[\"strategy_gross\", \"benchmark_gross\", \"long_gross\", \"short_gross\"]].columns,\n", "           prop = {\"size\": 15})\n", "plt.title(\"Decomposition of out of sample performance\", size = 22)\n", "plt.ylabel(\"Cumulative Return\", size = 15)\n", "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n", "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n", "plt.xticks(size = 13)\n", "plt.yticks(size = 13)\n", "plt.savefig(\"plots/outofsamlpe_brekdown.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #Stock Weights Index vs. Constrained & Unconstrained Optimization\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["width = 0.3\n", "fig, ax = plt.subplots(figsize = (15,10))\n", "ind = np.arange(len(stocks_invest))\n", "ax.barh(ind, stocks_invest.weights, width, label = \"Strategy Weights\")\n", "ax.barh(ind + width, stocks_invest.index_weights, width, label = \"Index Weights\")\n", "ax.barh(ind + 2* width, stocks_invest.weights_unconst, width, label = \"Unconstrained Strategy Weights\")\n", "ax.set(yticks = ind + width, yticklabels = stocks_invest.Name)\n", "ax.legend(prop={'size': 10})\n", "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.title(\"Stock Weights Strategy vs Index\", size = 25)\n", "plt.yticks(size = 10)\n", "plt.xticks(size = 15, ticks = np.arange(-0.4, 0.6, 0.1))\n", "plt.savefig(\"plots/strategy_weights.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["             #Plot Country Weights Index vs. Strategy\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["country_weights_strategy = stocks_invest[[\"Country\", \"weights\"]].groupby(by = \"Country\").sum()\n", "country_weights_index = stocks_index[[\"Country\", \"index_weights\"]].groupby(by = \"Country\").sum()\n", "country_weights = country_weights_index.join(country_weights_strategy).fillna(0)\n", "country_weights = pd.DataFrame(country_weights, index = country_weights_index.index)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ssemble plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["width = 0.3\n", "fig, ax = plt.subplots(figsize = (15,10))\n", "ind = np.arange(len(country_weights))\n", "ax.barh(ind, country_weights.weights, width, label = \"Strategy Weights\")\n", "ax.barh(ind + width, country_weights.index_weights, width, label = \"Index Weights\")\n", "ax.set(yticks = ind + width, yticklabels = country_weights.index)\n", "ax.legend(prop={'size': 15})\n", "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.title(\"Country Weights Strategy vs Index\", size = 25)\n", "plt.yticks(size = 15)\n", "plt.xticks(size = 15)\n", "plt.savefig(\"plots/country_weights.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------<br>\n", "lot Currency weights index vs. Strategy<br>\n", "--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["values = stocks_index.join(stocks_invest[\"weights\"]).fillna(0)\n", "currency_weights_strategy = values[[\"Currency\", \"weights\"]].groupby(by = \"Currency\").sum()\n", "currency_weights_index = values[[\"Currency\", \"index_weights\"]].groupby(by = \"Currency\").sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["currency_weights = currency_weights_index.join(currency_weights_strategy).fillna(0)\n", "currency_weights = currency_weights.rename(index = {\"GBp\": \"GBP\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ssemble plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["width = 0.4\n", "fig, ax = plt.subplots()\n", "ind = np.arange(len(currency_weights_index))\n", "ax.barh(ind, currency_weights.weights, width, label = \"Strategy Weights\")\n", "ax.barh(ind + width, currency_weights.index_weights, width, label = \"Index Weights\")\n", "ax.set(yticks = ind + width, yticklabels = currency_weights.index)\n", "ax.legend([\"Strategy\", \"Index\"])\n", "plt.title(\"Currency Weights Strategy vs Index\", size = 20)\n", "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.yticks(size = 15)\n", "plt.xticks(size = 15)\n", "plt.savefig(\"plots/curency_comparison.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["                #Plot sector weights strategy vs. index\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sector_weights_strategy = stocks_invest[[\"Sector\", \"weights\"]].groupby(by = \"Sector\").sum()\n", "sector_weights_index = stocks_index[[\"Sector\", \"index_weights\"]].groupby(by = \"Sector\").sum()\n", "sector_weights = sector_weights_index.join(sector_weights_strategy)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ssemble plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["width = 0.4\n", "fig, ax = plt.subplots(figsize=(15, 10))\n", "ind = np.arange(len(sector_weights))\n", "ax.barh(ind, sector_weights.index_weights, width, label = \"Strategy Weights\")\n", "ax.barh(ind + width, sector_weights.weights, width, label = \"Index Weights\")\n", "ax.set(yticks = ind + width, yticklabels = sector_weights.index)\n", "ax.legend(prop = {\"size\": 20})\n", "plt.title(\"Sector Weights Strategy vs Index\", size = 25)\n", "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.yticks(size = 15)\n", "plt.xticks(size = 15)\n", "plt.subplots_adjust(left = 0.2)\n", "plt.savefig(\"plots/sector_weights.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #Plot performance Nasdaq100 vs. MSCI World vs. FTSE AW-HighDivYield\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ownload prices and clean data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prices = yf.download(tickers = [\"VHYL.AS\", \"EXXT.DE\", \"IWDA.AS\"], start = \"2022-01-01\", end = dt.date.today())\n", "prices = prices[\"Adj Close\"]\n", "prices = prices.div(prices.iloc[0])\n", "prices = prices.rename(columns = {\"EXXT.DE\": \"Nasdaq 100\", \"IWDA.AS\": \"MSCI World\", \"VHYL.AS\": \"FTSE All World High Dividend\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ssemble plot"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 10))\n", "plt.plot(prices)\n", "plt.title(\"High Dividend Stocks vs. Technology Stocks vs. Total Market\", size = 25)\n", "plt.legend(prices.columns,  prop={'size': 15})\n", "plt.ylabel(\"Cumulative Return\", size = 15)\n", "plt.xticks(size = 15)\n", "plt.yticks(size = 15)\n", "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))\n", "plt.gca().xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n", "plt.savefig(\"comparison.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    #calculate change of correlation  matrix in vs out of sample\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_cor = Gross_Price[Gross_Price.index > end_backtesting].pct_change().corr()\n", "in_sample_cor =  Gross_Price[Gross_Price.index < end_backtesting].pct_change().corr()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rel_cor = out_sample_cor / in_sample_cor\n", "pd.DataFrame(rel_cor).to_csv(\"files/correlation_change.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["  #calculate performance ratios for short and long portfolios & Benchmark\n", "#---------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "we only include stocks which contain a forward,trailing PE ratio &<br>\n", "PB Ratio to calculate weighted values. <br>\n", "Further, as described by iShares,<br>\n", "we restrict the maximum value of PE ratios to 60 and of PB ratios to 25. <br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks_short = stocks_invest[stocks_invest.weights <0]\n", "stocks_long = stocks_invest[stocks_invest.weights > 0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ividend yield"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["div_yield_long = (stocks_long.weights / stocks_long.weights.sum() * stocks_long.Yield).sum()\n", "div_yield_short = (stocks_short.weights.abs()/ stocks_short.weights.abs().sum() * stocks_short.Yield).sum()\n", "div_yield_index = (stocks_index.index_weights * stocks_index.Yield).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["railing PE Ratio, forward PE, PB Ratio"]}, {"cell_type": "markdown", "metadata": {}, "source": ["et all stocks and join strategy weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index = stocks_index.join(stocks_invest[[\"weights\"]])"]}, {"cell_type": "markdown", "metadata": {}, "source": [". remove stocks where ratios are not given"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index = index[index.Trailing_PE.notna()]\n", "index = index[index.Forward_PE.notna()]"]}, {"cell_type": "markdown", "metadata": {}, "source": [". set PE ratios above 60 to 60, set PB ratios above 25 to 25"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index.Trailing_PE = np.where(index.Trailing_PE > 60, 60, index.Trailing_PE)\n", "index.Forward_PE = np.where(index.Forward_PE > 60, 60, index.Forward_PE)\n", "index.PB_Ratio = np.where(index.PB_Ratio > 25, 25, index.PB_Ratio)"]}, {"cell_type": "markdown", "metadata": {}, "source": [". separate long and short stocks from strategy to calculate ratios separately"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["short = index.loc[stocks_short.index]\n", "long = index.loc[stocks_long.index]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate Trailing PE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PE_long = (long.weights / long.weights.sum() * long.Trailing_PE).sum()\n", "PE_short = (short.weights / short.weights.sum() * short.Trailing_PE).sum()\n", "PE_index = (index.index_weights * index.Trailing_PE).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate forward PE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PE_fwd_long = (long.weights / long.weights.sum() * long.Forward_PE).sum()\n", "PE_fwd_short = (short.weights / short.weights.sum() * short.Forward_PE).sum()\n", "PE_fwd_index = (index.index_weights * index.Forward_PE).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate PB Ratio"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PB_long = (long.weights / long.weights.sum() * long.PB_Ratio).sum()\n", "PB_short = (short.weights / short.weights.sum() * short.PB_Ratio).sum()\n", "PB_index = (index.index_weights * index.PB_Ratio).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ssemble metrics dataframe"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_short = {\"Yield\": to_pct(div_yield_short,2),\n", "                \"Price_Book\": round(PB_short,2),\n", "                \"Trailing_PE\": round(PE_short,2),\n", "                \"Forward_PE\": round(PE_fwd_short,2)}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_long = {\"Yield\": to_pct(div_yield_long,2),\n", "               \"Price_Book\": round(PB_long,2),\n", "               \"Trailing_PE\": round(PE_long,2),\n", "               \"Forward_PE\": round(PE_fwd_long,2)}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_index = {\"Yield\": to_pct(div_yield_index,2),\n", "                \"Price_Book\": round(PB_index,2),\n", "                \"Trailing_PE\": round(PE_index,2),\n", "                \"Forward_PE\": round(PE_fwd_index,2)}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_table = pd.DataFrame({\"Portfolio Short\":ratios_short, \"Portfolio Long\": ratios_long, \"Index\": ratios_index})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["xport table"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfi.export(ratios_table, \"plots/portfolio_characteristics.png\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}