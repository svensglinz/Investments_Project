{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["oad libraries<br>\n", "--------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import yfinance as yf\n", "import pandas as pd\n", "import numpy as np\n", "import math as m\n", "import matplotlib.pyplot as plt\n", "import matplotlib.ticker as mtick\n", "from scipy.optimize import minimize\n", "from scipy.optimize import Bounds\n", "import datetime as dt\n", "from sklearn.linear_model import LinearRegression\n", "import dataframe_image as dfi"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine parameters of investment period start"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_backtesting = np.datetime64(\"2011-01-01\")\n", "end_backtesting = np.datetime64(\"2021-12-31\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["mport needed cleaned files<br>\n", "----------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["constituents = pd.read_csv(\"files/index_constituents_data.csv\", index_col= 0)\n", "benchmark = pd.read_csv(\"files/benchmark.csv\", index_col= 0)\n", "Gross_Price = pd.read_csv(\"files/Gross_Prices_EUR.csv\", index_col= 0)\n", "Net_Price = pd.read_csv(\"files/Net_Prices_EUR.csv\", index_col= 0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Gross_Price.index = pd.to_datetime(Gross_Price.index)\n", "Net_Price.index = pd.to_datetime(Net_Price.index)\n", "benchmark.index = pd.to_datetime(benchmark.index)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["elect stocks to invest in (10 highest dividend yields and 10 lowest dividend yields) & drop<br>\n", "HP stock for which dividends have not been calculated correctly"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["constituents = constituents.sort_values(by = \"Yield\", ascending= False)\n", "constituents = constituents.drop(\"BHP.L\")\n", "stocks = constituents.iloc[np.r_[0:10, 39:49]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["etreive in sample stock prices to calculate returns and var-cov matrix for optimization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Stock_Prices = Gross_Price[stocks.index.to_list()]\n", "in_sample = Stock_Prices[Stock_Prices.index < end_backtesting]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["stimate expected returns and var-cov matrix for optimization & delete variables which are not needed anymore (for better overview)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ER = in_sample.pct_change().mean()\n", "S = in_sample.pct_change().cov()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["efine functions for optimization (variance, return,  negative sharp ratio)<br>\n", "-----------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pvar(w, S):\n", "    return (w.T @ S @ w)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pret(w, ER):\n", "    return (w.T @ ER)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sharpe(w ,ER, S):\n", "    return -(w.T @ ER)/ ((w.T @ S @ w) ** 0.5)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate optimized portfolios<br>\n", "--------------------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["N = len(ER)\n", "x0 = np.ones(N)/N"]}, {"cell_type": "markdown", "metadata": {}, "source": ["et up constraints<br>\n", "irst contraint -> total investment = 100% long<br>\n", "econd constraint- > Values smaller than - min_weight (shocks which are shorted)<br>\n", "hird constraint -> Values larger than min_weight (stock which are longed)<br>\n", "ounds = maximum long and short % for stocks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["min_weight = 0.02"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cons_multiple = ({\"type\": \"eq\", \"fun\" : lambda x: np.sum(x) - 1},\n", "                {\"type\": \"ineq\", \"fun\" : lambda x: -min_weight -x[10:20]},\n", "                {\"type\": \"ineq\", \"fun\" : lambda x: x[0:10]- min_weight})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bounds = Bounds(-0.2, 0.2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["nly constraint for unconstrained portfolio --> Total stock weights == 100%"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cons_simple = ({\"type\": \"eq\", \"fun\" : lambda x: np.sum(x) - 1})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate optimized values (GMVP and MSRP constrained and unconstrained)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["GMVP_const = minimize(pvar, x0, method='SLSQP', args=S, constraints = cons_multiple,\n", "                      options={'disp': True, 'ftol': 1e-9}, bounds = bounds)\n", "GMVP_unconst = minimize(pvar, x0, method = \"SLSQP\", args = S,constraints = cons_simple,\n", "                        options={'disp': True, 'ftol': 1e-9})\n", "MSRP_const = minimize(sharpe, x0, method='SLSQP', args=(ER, S), constraints=cons_multiple,\n", "                      options={'disp': True, 'ftol': 1e-9}, bounds = bounds)\n", "MSRP_unconst = minimize(sharpe, x0, method='SLSQP', args=(ER,S), constraints = cons_simple,\n", "                        options={'disp': True, 'ftol': 1e-9})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["omplete data set of selected stocks with calculated constrained MSRP values & export for presentation"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks[\"weights\"] = MSRP_const.x\n", "stocks[\"weights_unconst\"] = MSRP_unconst.x\n", "dfi.export(stocks, \"plots/selected_portfolio_characteristics.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "alculate Strategy and Benchmark Returns in and out of Sample<br>\n", "###########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate change of correlation  matrix in and out of sample"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_cor = Stock_Prices[Stock_Prices.index > end_backtesting].pct_change().corr()\n", "in_sample_cor =  Stock_Prices[Stock_Prices.index < end_backtesting].pct_change().corr()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rel_cor = out_sample_cor / in_sample_cor\n", "pd.DataFrame(rel_cor).to_csv(\"files/correlation_change.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["AILY Net Returns / Gross Returns / Net & Gross for long & Short individually over total period"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Net_Returns = Net_Price[stocks.index].pct_change() + 1\n", "Gross_Returns = Gross_Price[stocks.index].pct_change() + 1\n", "Gross_Returns_short = Gross_Price[stocks[stocks.weights < 0].index].pct_change() + 1\n", "Gross_Returns_long = Gross_Price[stocks[stocks.weights > 0].index].pct_change() + 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["n sample returns CUMULATIVE"]}, {"cell_type": "markdown", "metadata": {}, "source": [". Daily Returns over in Sample Period"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample_net = Net_Returns[Net_Returns.index < end_backtesting]\n", "in_sample_gross = Gross_Returns[Gross_Returns.index < end_backtesting]\n", "in_sample_short_gross = Gross_Returns_short[Gross_Returns_short.index < end_backtesting]\n", "in_sample_long_gross = Gross_Returns_long[Gross_Returns_long.index < end_backtesting]"]}, {"cell_type": "markdown", "metadata": {}, "source": [". standardize initial stock prices to 1, multiply by strategy weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample_net.iloc[0] = MSRP_const.x\n", "in_sample_gross.iloc[0] = MSRP_const.x\n", "in_sample_long_gross.iloc[0] = stocks.weights[stocks.weights > 0] / stocks.weights[stocks.weights > 0].sum()\n", "in_sample_short_gross.iloc[0] = np.abs(stocks.weights[stocks.weights < 0]) / np.abs(stocks.weights[stocks.weights < 0].sum())"]}, {"cell_type": "markdown", "metadata": {}, "source": [". take cumulative product of initial investment and daily returns to get relative values of stocks in strategy over time<br>\n", "um up all values and get total value of strategy over time (indexed to 1 at start)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample_net = in_sample_net.cumprod().sum(axis = 1)\n", "in_sample_gross = in_sample_gross.cumprod().sum(axis = 1)\n", "in_sample_long_gross = in_sample_long_gross.cumprod().sum(axis = 1)\n", "in_sample_short_gross = in_sample_short_gross.cumprod().sum(axis = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": [". combine all returns to data frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample = pd.DataFrame({\"strategy_net\": in_sample_net, \"strategy_gross\": in_sample_gross,\n", "                          \"gross_long\": in_sample_long_gross, \"gross_short\": in_sample_short_gross},\n", "                         index = in_sample_net.index)"]}, {"cell_type": "markdown", "metadata": {}, "source": [". add relative benchmark returns to data frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample = in_sample.join(benchmark)\n", "in_sample[[\"benchmark_gross\", \"benchmark_net\"]] = in_sample[[\"benchmark_gross\", \"benchmark_net\"]].div(in_sample[[\"benchmark_gross\", \"benchmark_net\"]].iloc[0])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ut of sample returns CUMULATIVE"]}, {"cell_type": "markdown", "metadata": {}, "source": [". Daily Returns over out of Sample Period"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_net = Net_Returns[Net_Returns.index > end_backtesting]\n", "out_sample_gross = Gross_Returns[Gross_Returns.index > end_backtesting]\n", "out_sample_short_gross = Gross_Returns_short[Gross_Returns_short.index > end_backtesting]\n", "out_sample_long_gross = Gross_Returns_long[Gross_Returns_long.index > end_backtesting]"]}, {"cell_type": "markdown", "metadata": {}, "source": [". standardize initial stock prices to 1, multiply by strategy weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_net.iloc[0] = MSRP_const.x\n", "out_sample_gross.iloc[0] = MSRP_const.x\n", "out_sample_long_gross.iloc[0] = stocks.weights[stocks.weights > 0] / stocks.weights[stocks.weights > 0].sum()\n", "out_sample_short_gross.iloc[0] = np.abs(stocks.weights[stocks.weights < 0]) / np.abs(stocks.weights[stocks.weights < 0].sum())"]}, {"cell_type": "markdown", "metadata": {}, "source": [". take cumulative product of initial investment and daily returns to get relative values of stocks in strategy over time<br>\n", "um up all values and get total value of strategy over time (indexed to 1 at start)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_net = out_sample_net.cumprod().sum(axis = 1)\n", "out_sample_gross = out_sample_gross.cumprod().sum(axis = 1)\n", "out_sample_long_gross = out_sample_long_gross.cumprod().sum(axis = 1)\n", "out_sample_short_gross = out_sample_short_gross.cumprod().sum(axis = 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": [". combine all returns to data frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample = pd.DataFrame({\"strategy_net\": out_sample_net, \"strategy_gross\": out_sample_gross,\n", "                           \"long_gross\": out_sample_long_gross, \"short_gross\": out_sample_short_gross},\n", "                         index = out_sample_gross.index)"]}, {"cell_type": "markdown", "metadata": {}, "source": [". add relative benchmark returns to data frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample = out_sample.join(benchmark)\n", "out_sample[[\"benchmark_gross\", \"benchmark_net\"]] = out_sample[[\"benchmark_gross\", \"benchmark_net\"]].div(out_sample[[\"benchmark_gross\", \"benchmark_net\"]].iloc[0])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate contribution of all stocks to excess / shortfall return of strategy vs. Benchmark"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate returns over out of sample periods for all stocks in index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_all = Gross_Price[Gross_Price.index > end_backtesting]\n", "out_sample_all = out_sample_all.pct_change() + 1\n", "out_sample_all = out_sample_all.fillna(1).cumprod()\n", "out_return_all = out_sample_all.iloc[len(out_sample_all.index)-1].div(out_sample_all.iloc[0]) - 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "reate Plots<br>\n", "###########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate excess return contribution as (Weight Strategy - Weigh Index) * Return"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ret_contrib = constituents.join(stocks[\"weights\"]).fillna(0)\n", "ret_contrib[\"diff_weights\"] = ret_contrib[\"weights\"] - ret_contrib[\"index_weights\"]\n", "ret_contrib = ret_contrib.join(pd.DataFrame(out_return_all))\n", "ret_contrib = ret_contrib.rename(columns = {0: \"return\"})\n", "ret_contrib[\"diff_return\"] = ret_contrib[\"diff_weights\"] * ret_contrib[\"return\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot and save results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 10))\n", "ax = fig.add_subplot(1,1,1)\n", "plt.bar(ret_contrib.Name[0:10], ret_contrib.diff_return[0:10])\n", "plt.bar(ret_contrib.Name[10:39], ret_contrib.diff_return[10:39])\n", "plt.bar(ret_contrib.Name[39:49], ret_contrib.diff_return[39:49])\n", "plt.legend([\"Long\", \"Not Invested\", \"Short\"])\n", "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.title(\"Decomposition of out of Sample excess Returns\", size = 20)\n", "plt.ylabel(\"Excess Return Strategy vs. Benchmark\")\n", "plt.subplots_adjust(bottom = 0.3)\n", "plt.xticks(rotation=90)\n", "plt.savefig(\"plots/excess_return_breakdown.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ut of sample strategy vs. benchmark"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fig = plt.figure(figsize=(15, 10))\n", "plt.plot(out_sample[[\"strategy_gross\", \"benchmark_gross\"]])\n", "plt.legend(out_sample[[\"strategy_gross\", \"benchmark_gross\"]].columns)\n", "plt.title(\"Out of Sample Strategy Performance\", size = 20)\n", "plt.ylabel(\"Cumulative Return\")\n", "plt.xlabel(\"Date\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.savefig(\"plots/outofsample_performance.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["n sample strategy vs. benchmark"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(in_sample[[\"strategy_gross\", \"benchmark_gross\"]])\n", "plt.legend(in_sample[[\"strategy_gross\", \"benchmark_gross\"]].columns)\n", "plt.title(\"In Sample Strategy Performance\", size = 20)\n", "plt.ylabel(\"Cumulative Return\")\n", "plt.xlabel(\"Date\")\n", "plt.savefig(\"plots/insample_performance.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["how strategy returns net vs. gross (shows importance of dividend yield)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(in_sample[[\"strategy_gross\", \"strategy_net\", \"benchmark_gross\", \"benchmark_net\"]])\n", "plt.legend(in_sample[[\"strategy_gross\", \"strategy_net\", \"benchmark_gross\", \"benchmark_net\"]].columns)\n", "plt.title(\"In Sample Strategy Performance (net and gross) Comparison\", size = 15)\n", "plt.ylabel(\"Cumulative Return\")\n", "plt.xlabel(\"Date\")\n", "plt.savefig(\"plots/insample_performance_netgross.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot out of sample short vs long (shows that we outperformed benchmark in both portfolios -> show detailed breakdown)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.plot(out_sample[[\"strategy_gross\", \"benchmark_gross\", \"long_gross\", \"short_gross\"]])\n", "plt.legend(out_sample[[\"strategy_gross\", \"benchmark_gross\", \"long_gross\", \"short_gross\"]].columns)\n", "plt.title(\"Decomposition of out of sample performance\", size = 20)\n", "plt.ylabel(\"Cumulative Return\")\n", "plt.xlabel(\"Date\")\n", "plt.savefig(\"plots/outofsamlpe_brekdown.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot weights for different optimization techniques (GMVP, MSRP (constrained and unconstrained)<br>\n", "XXXXXXXXXXX"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot dividend yields of picked stocks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.bar(constituents.Name[0:10], height = constituents.Yield[0:10])\n", "plt.bar(constituents.Name[10:39], height = constituents.Yield[10:39])\n", "plt.bar(constituents.Name[39:49], height = constituents.Yield[39:49])\n", "plt.xticks(rotation=90)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot strategy weights vs index weights vs unconstrained optimization weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["width = 0.3\n", "fig, ax = plt.subplots(figsize = (15,10))\n", "ind = np.arange(len(stocks))\n", "ax.barh(ind, stocks.weights, width, label = \"Strategy Weights\")\n", "ax.barh(ind + width, stocks.index_weights, width, label = \"Index Weights\")\n", "ax.barh(ind + 2* width, stocks.weights_unconst, width, label = \"Unconstrained Strategy Weights\")\n", "ax.set(yticks = ind + width, yticklabels = stocks.Name)\n", "ax.legend(prop={'size': 10})\n", "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n", "plt.title(\"Stock Weights Strategy vs Index\", size = 25)\n", "plt.xlabel(\"weights in %\", size = 15)\n", "plt.savefig(\"plots/strategy_weights.png\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["country_weights = stocks[[\"Country\", \"weights\"]].groupby(by = \"Country\").sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot currencies"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["constituents = constituents.join(stocks[\"weights\"]).fillna(0)\n", "currency_weights_strategy = constituents[[\"Currency\", \"weights\"]].groupby(by = \"Currency\").sum()\n", "currency_weights_index = constituents[[\"Currency\", \"index_weights\"]].groupby(by = \"Currency\").sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["currency_weights = currency_weights_index.join(currency_weights_strategy).fillna(0)\n", "currency_weights = currency_weights.rename(index = {\"GBp\": \"GBP\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ie chart of currency weights in strategy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.pie(currency_weights.weights.loc[currency_weights.weights > 0], labels= currency_weights.weights.loc[currency_weights.weights > 0].index, autopct='%1.1f%%')\n", "plt.savefig(\"currency_pie_strategy.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot currency weights stragety vs index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["width = 0.4\n", "fig, ax = plt.subplots()\n", "ind = np.arange(len(currency_weights_index))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ax.barh(ind, currency_weights.weights, width, label = \"Strategy Weights\")\n", "ax.barh(ind + width, currency_weights.index_weights, width, label = \"Index Weights\")\n", "ax.set(yticks = ind + width, yticklabels = currency_weights.index)\n", "ax.legend([\"Strategy\", \"Index\"])\n", "plt.title(\"Currency Weights Strategy vs Index\", size = 20)\n", "plt.xlabel(\"weight in %\")\n", "plt.savefig(\"curency_comparison.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot industries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["sector_weights_strategy = stocks[[\"Sector\", \"weights\"]].groupby(by = \"Sector\").sum()\n", "sector_weights_index = constituents[[\"Sector\", \"index_weights\"]].groupby(by = \"Sector\").sum()\n", "sector_weights = sector_weights_index.join(sector_weights_strategy)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["width = 0.4\n", "fig, ax = plt.subplots(figsize=(15, 10))\n", "ind = np.arange(len(sector_weights))\n", "ax.barh(ind, sector_weights.index_weights, width, label = \"Strategy Weights\")\n", "ax.barh(ind + width, sector_weights.weights, width, label = \"Index Weights\")\n", "ax.set(yticks = ind + width, yticklabels = sector_weights.index)\n", "ax.legend(prop = {\"size\": 20})\n", "plt.xlabel(\"weight in %\")\n", "plt.title(\"Sector Weights Strategy vs Index\", size = 20)\n", "plt.savefig(\"sector_weights.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot ftse all world high dividend index vs nasdaq 100 vs msci world(both quoted in euros)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["prices = yf.download(tickers = [\"VHYL.AS\", \"EXXT.DE\", \"IWDA.AS\"], start = \"2022-01-01\", end = dt.date.today())\n", "prices = prices[\"Adj Close\"]\n", "prices = prices.div(prices.iloc[0])\n", "prices = prices.rename(columns = {\"EXXT.DE\": \"Nasdaq 100\", \"IWDA.AS\": \"MSCI World\", \"VHYL.AS\": \"FTSE All World High Dividend\"})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 10))\n", "plt.plot(prices)\n", "plt.title(\"High Dividend Stocks vs. Technology Stocks vs Total Market\", size = 20)\n", "plt.legend(prices.columns,  prop={'size': 20})\n", "plt.ylabel(\"Cumulative Return\")\n", "plt.xlabel(\"Date\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.savefig(\"comparison.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["###########################################################################<br>\n", "alculate Performance Ratios of Strategy and Index (in and out of Sample)<br>\n", "###########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["nputs: ER = expected daily returns<br>\n", "d = expected daily standard deviation of reurns<br>\n", "nnzalized risk free rate<br>\n", "umber of days over which sharp ratio shall be calculated"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sharp_ratio(ER, Sd, Rf, days):\n", "    SR = (ER-Rf/days)/Sd * m.sqrt(days)\n", "    return(SR)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rf_rate = 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SR_bm_in_sample = sharp_ratio(ER = in_sample[\"benchmark_gross\"].pct_change().mean()\n", "                              , Sd = in_sample[\"benchmark_gross\"].pct_change().std(),\n", "                              Rf = rf_rate, days = 250)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SR_bm_out_sample = sharp_ratio(ER = out_sample[\"benchmark_gross\"].pct_change().mean(),\n", "                               Sd = out_sample[\"benchmark_gross\"].pct_change().std(),\n", "                               Rf = rf_rate, days = 250)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SR_strategy_in_sample = sharp_ratio(ER = in_sample[\"strategy_gross\"].pct_change().mean(),\n", "                                    Sd = in_sample[\"strategy_gross\"].pct_change().std(),\n", "                                    Rf = rf_rate, days = 250)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SR_strategy_out_sample = sharp_ratio(ER = out_sample[\"strategy_gross\"].pct_change().mean(),\n", "                                     Sd = out_sample[\"strategy_gross\"].pct_change().std(),\n", "                                     Rf = rf_rate, days = 250)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate yearly volatility over observation period"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["vol_BM_in = m.sqrt(in_sample[\"benchmark_gross\"].pct_change().var() * 250)\n", "vol_BM_out = m.sqrt(out_sample[\"benchmark_gross\"].pct_change().var() * 250)\n", "vol_strategy_in = m.sqrt(in_sample[\"strategy_gross\"].pct_change().var() * 250)\n", "vol_strategy_out = m.sqrt(out_sample[\"strategy_gross\"].pct_change().var() * 250)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["otal returns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ret_BM_in\n", "ret_BM_out\n", "ret_strategy_in\n", "ret_strategy_out"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculat monthly betas and alphas for strategy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["aily returns in sample"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_returns_strategy_in = in_sample[\"strategy_gross\"].pct_change().fillna(0) + 1\n", "daily_returns_BM_in = in_sample[\"benchmark_gross\"].pct_change().fillna(0) + 1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["daily_returns_strategy_out = out_sample[\"strategy_gross\"].pct_change().fillna(0) + 1\n", "daily_returns_BM_out = out_sample[\"benchmark_gross\"].pct_change().fillna(0) + 1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["onvert to monthly returns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_in = daily_returns_strategy_in.groupby(pd.Grouper(freq='M')).prod().to_numpy().reshape((-1,1)) -1\n", "x_in = daily_returns_BM_in.groupby(pd.Grouper(freq='M')).prod().to_numpy().reshape((-1,1)) -1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_out = daily_returns_strategy_out.groupby(pd.Grouper(freq='M')).prod().to_numpy().reshape((-1,1)) -1\n", "x_out = daily_returns_BM_out.groupby(pd.Grouper(freq='M')).prod().to_numpy().reshape((-1,1)) -1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate regression parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_in = LinearRegression().fit(x_in,y_in)\n", "model_out = LinearRegression().fit(x_out, y_out)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["etreive beta and alpha"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["in_sample_beta = model_in.coef_\n", "in_sample_alpha = model_in.intercept_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["out_sample_beta = model_out.coef_\n", "out_sample_alpha = model_out.intercept_"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot regression line (MODIFY)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(y_out, x_out)\n", "plt.scatter(x_in, y_in)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate maximum drawdown"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["maxdd_BM_in = np.min(in_sample.diff().cumsum().benchmark_gross)\n", "maxdd_BM_out =np.min(out_sample.diff().cumsum().benchmark_gross)\n", "maxdd_strategy_in  = np.min(in_sample.diff().cumsum().strategy_gross)\n", "maxdd_strategy_out = np.min(out_sample.diff().cumsum().strategy_gross)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate performance ratios for short and long portfolios"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks_short = stocks[stocks.weights <0]\n", "stocks_long = stocks[stocks.weights > 0]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ividend yield"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["div_yield_long = (stocks_long.weights / stocks_long.weights.sum() * stocks_long.Yield).sum()\n", "div_yield_short = (stocks_short.weights.abs()/ stocks_short.weights.abs().sum() * stocks_short.Yield).sum()\n", "div_yield_index = (constituents.index_weights * constituents.Yield).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["railing PE Ratio, forward PE, PB Ratio"]}, {"cell_type": "markdown", "metadata": {}, "source": ["et all stocks and join strategy weights"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index = constituents.join(stocks[[\"weights\"]])"]}, {"cell_type": "markdown", "metadata": {}, "source": [". remove stocks where ratios are not given"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index = index[index.Trailing_PE.notna()]\n", "index = index[index.Forward_PE.notna()]"]}, {"cell_type": "markdown", "metadata": {}, "source": [". set PE ratios above 60 to 60, set PB ratios above 25 to 25"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["index.Trailing_PE = np.where(index.Trailing_PE > 60, 60, index.Trailing_PE)\n", "index.Forward_PE = np.where(index.Forward_PE > 60, 60, index.Forward_PE)\n", "index.PB_Ratio = np.where(index.PB_Ratio > 25, 25, index.PB_Ratio)"]}, {"cell_type": "markdown", "metadata": {}, "source": [". separate long and short stocks from strategy to calculate ratios separately"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["short = index.loc[stocks_short.index]\n", "long = index.loc[stocks_long.index]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate Trailing PE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PE_long = (long.weights / long.weights.sum() * long.Trailing_PE).sum()\n", "PE_short = (short.weights / short.weights.sum() * short.Trailing_PE).sum()\n", "PE_index = (index.index_weights * index.Trailing_PE).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate forward PE"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PE_fwd_long = (long.weights / long.weights.sum() * long.Forward_PE).sum()\n", "PE_fwd_short = (short.weights / short.weights.sum() * short.Forward_PE).sum()\n", "PE_fwd_index = (index.index_weights * index.Forward_PE).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate PB Ratio"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PB_long = (long.weights / long.weights.sum() * long.PB_Ratio).sum()\n", "PB_short = (short.weights / short.weights.sum() * short.PB_Ratio).sum()\n", "PB_index = (index.index_weights * index.PB_Ratio).sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ssemble metrics dataframe"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_short = {\"Yield\": div_yield_short, \"Price_Book\": PB_short, \"Trailing_PE\": PE_short,\n", "                \"Forward_PE\": PE_fwd_short}\n", "ratios_long = {\"Yield\": div_yield_long, \"Price_Book\": PB_long, \"Trailing_PE\": PE_long,\n", "                \"Forward_PE\": PE_fwd_long}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_index = {\"Yield\": div_yield_index, \"Price_Book\": PB_index, \"Trailing_PE\": PE_index,\n", "                \"Forward_PE\": PE_fwd_index}"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ratios_table = pd.DataFrame({\"Portfolio Short\":ratios_short, \"Portfolio Long\": ratios_long, \"Index\": ratios_index})\n", "ratios_table = ratios_table.round(3)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["xport table"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dfi.export(ratios_table, \"portfolio_characteristics.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lso check for correlation breakdowns etc..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["imulate constrained efficient frontier!<br>\n", "-----------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate volatility and expected return of GMVP and MSRP constrained"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["GMVP_const_ER = pret(w = GMVP_const.x, ER = ER) * 250\n", "GMVP_const_VAR = m.sqrt(pvar(w = GMVP_const.x, S = S) * 250)\n", "MSRP_const_ER =  pret(w = MSRP_const.x, ER = ER) * 250\n", "MSRP_const_VAR = m.sqrt(pvar(w = MSRP_const.x, S = S) * 250)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["imulate minimum varaince frontier by minimizing the negative of the expected portfolio return<br>\n", "iven a deterministic variance and the same restrictions as above.<br>\n", "e loop over an array of variances and can thus numerically get the MVF"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def pret_sim(w, ER):\n", "    return (-(w.T @ ER))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["ariances to loop over"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["a = np.arange(0.1, 0.6, 0.01)\n", "bounds = Bounds(-0.2, 0.2)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["nitialize lists to store results in"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MVF_var_const = []\n", "MVF_ret_const = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["oop over variances and maximize expected return given that portfolio variance = given variance"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in a:\n", "    max_var = i\n", "    cons = ({\"type\": \"eq\", \"fun\" : lambda x: np.sum(x) - 1},\n", "            {\"type\": \"eq\", \"fun\" : lambda x: m.sqrt((x.T @ S @ x)* 250) - max_var},\n", "            {\"type\": \"ineq\", \"fun\": lambda x: -min_weight - x[10:20]},\n", "            {\"type\": \"ineq\", \"fun\": lambda x: x[0:10] - min_weight})\n", "    maximized = minimize(pret_sim, x0, method='SLSQP', args= ER, options={'disp': True, 'ftol': 1e-9}, constraints=cons, bounds = bounds)\n\n", "    #only store result if optimization was successful!\n", "    if maximized.success:\n", "        MVF_var_const.append(i)\n", "        MVF_ret_const.append(maximized.fun * -250)\n", "    else:\n", "        continue"]}, {"cell_type": "markdown", "metadata": {}, "source": ["imulate random constrained portfolios<br>\n", "e simulate random portfolios which fulfil all restrictions by minimzing a \"random\" function which uses a random<br>\n", "rray and the modulus to generate different portfolios<br>\n", "---------------------------------------------------------------------------------------"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["random_portfolio = []"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def rand_funct(x,y):\n", "    return ((x % y)/y).sum()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cons = ({\"type\": \"eq\", \"fun\" : lambda x: np.sum(x) - 1},\n", "        {\"type\": \"ineq\", \"fun\": lambda x: -min_weight - x[10:20]},\n", "        {\"type\": \"ineq\", \"fun\": lambda x: x[0:10] - min_weight})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["i = 0\n", "while i < 60:\n", "    y = np.random.uniform(low= 0, high=1, size=20)\n", "    MSRP_sim = minimize(rand_funct, x0, method='SLSQP', args= y, constraints=cons, options={'disp': True, 'ftol': 1e-9}, bounds = bounds)\n", "    i = i + 1\n\n", "    #only store successful optimizations\n", "    if MSRP_sim.success:\n", "        random_portfolio.append(MSRP_sim.x)\n", "    else:\n", "        continue"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MVF_randvar_const = []\n", "MVF_randret_const = []"]}, {"cell_type": "markdown", "metadata": {}, "source": ["alculate return and variance (yearly) from calculated \"random\" portfolios"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in range(len(random_portfolio)):\n", "    exp_return = pret(w = random_portfolio[i], ER = ER)\n", "    exp_var = pvar(w = random_portfolio[i], S = S)\n", "    exp_return_year = exp_return * 250\n", "    exp_var_year = m.sqrt(exp_var * 250)\n", "    MVF_randvar_const.append(exp_var_year)\n", "    MVF_randret_const.append(exp_return_year)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MVF_var_const.insert(0, GMVP_const_VAR)\n", "MVF_ret_const.insert(0, GMVP_const_ER)\n", "CAL_x = np.linspace(0, MSRP_const_VAR + 0.2, 50, endpoint=True)\n", "SR_MSRP = MSRP_const_ER / MSRP_const_VAR\n", "CAL_y = 0 + SR_MSRP*CAL_x"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["frontier_points = pd.DataFrame({\"variance\": MVF_var_const, \"return\": MVF_ret_const})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["max_ret_index = frontier_points[\"return\"].idxmax()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["lot part that goes down again grey!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(15, 10))\n", "plt.plot(frontier_points.variance.iloc[0:max_ret_index + 1], frontier_points[\"return\"].iloc[0:max_ret_index + 1])\n", "plt.plot(frontier_points.variance.iloc[max_ret_index: len(frontier_points)],\n", "         frontier_points[\"return\"].iloc[max_ret_index: len(frontier_points)], color = \"grey\", ls =  \"--\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.scatter(MVF_randvar_const, MVF_randret_const)\n", "plt.scatter(GMVP_const_VAR, GMVP_const_ER, s = 70)\n", "plt.scatter(MSRP_const_VAR, MSRP_const_ER, s = 70)\n", "plt.plot(CAL_x, CAL_y)\n", "plt.xlim([0,0.4])\n", "plt.ylim([0,0.3])\n", "plt.title(\"Minimum Variance Frontier Simulated\", size = 22)\n", "plt.xlabel(\"Volatility\", size = 12)\n", "plt.ylabel(\"Return\", size = 12)\n", "plt.legend([\"Minimum Variance Frontier\", \"?\", \"Capital Allocation Line\",\"random portfolios\", \"GMVP\", \"MSRP\"],\n", "           prop={'size': 10})\n", "plt.savefig(\"minimumvariancefrontier.png\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}