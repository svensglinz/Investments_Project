{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "This file assembles a data frame which contains all stocks from the stoxx europe 50 index<br>\n", "and includes various stock ratios such as PE/ PB ratios, dividend yield as of 31.12.2021 etc.<br>\n", "Further, we download the prices of all index constituents and the index itself<br>\n", "and modify them to get the gross values (incl. dividends)<br>\n", "We export all prices as csv files which can be used as inputs for the script \"calculation.py\"<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["load libraries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import yfinance as yf\n", "import pandas as pd\n", "import numpy as np\n", "import time\n", "from yahoo_fin.stock_info import *\n", "import random"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##########################################################################<br>\n", "define parameters of investment period start<br>\n", "##########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["tart_backtesting is the minimum value. As it turns out, one of the stocks in our portfolio<br>\n", "nly IPO'd in 2019 and thus, our in-sampel period is accordingly cut short."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["start_backtesting = np.datetime64(\"2011-01-01\")\n", "end_backtesting = np.datetime64(\"2021-12-31\")\n", "end_out_sample = np.datetime64(\"2022-05-21\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["define end backtesting - one year as interval to calculate one year dividend yield"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["end_dividends = np.datetime64(\"2021-12-31\")\n", "start_dividends = end_dividends - np.timedelta64(365, 'D')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##########################################################################<br>\n", "Import benchmark and calculate net and gross values<br>\n", "##########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "ishares ETF on Stoxx Europe 50 used as benchmark (ETF is distributing --> paid out dividends were downloaded<br>\n", "separately and are stored in file \"dividends_benchmark.csv\" which is needed to calculate gross returns<br>\n", "with reinvested dividends)<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["benchmark = yf.download(tickers=\"EUNA.AS\", interval=\"1d\", start=start_backtesting, end=end_out_sample)\n", "benchmark_dividends = pd.read_csv(\"files/dividends_benchmark.csv\")\n", "benchmark_dividends.index = pd.to_datetime(benchmark_dividends.Date, format=\"%d.%m.%Y\")\n", "benchmark_dividends = benchmark_dividends.drop(\"Date\", axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["benchmark_net = pd.DataFrame(benchmark[\"Adj Close\"])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["calculate gross index with immediate reinvesting of all dividends"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["benchmark_gross = benchmark_net.join(benchmark_dividends)\n", "benchmark_gross[\"share_purchased\"] = benchmark_gross.Dividend / benchmark_gross[\"Adj Close\"]\n", "benchmark_gross.share_purchased = benchmark_gross.share_purchased.fillna(0)\n", "benchmark_gross.share_purchased = benchmark_gross.share_purchased.cumsum()\n", "benchmark_gross.share_purchased = benchmark_gross.share_purchased + 1\n", "benchmark_gross = benchmark_gross[\"Adj Close\"] * benchmark_gross.share_purchased"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["benchmark_gross = pd.DataFrame({\"Adj Close\": benchmark_gross})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["write CSV for replicability"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["benchmark = pd.DataFrame({\"benchmark_gross\": benchmark_gross[\"Adj Close\"], \"benchmark_net\": benchmark_net[\"Adj Close\"]},\n", "                         index=benchmark_net.index)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["benchmark.to_csv(\"files/benchmark.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["--------------------------------------------------------------------------------------------------"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "Download ticker symbols for investment universe which is the stoxx europe 50 index.<br>\n", "as there are no ticker symbols available on the webpage do the following:<br>\n", "1: download names of index constituents from wikipedia<br>\n", "2: download names and ticker of euro stoxx 50 from wikipedia<br>\n", "3: join the two since many constituents are overlapping<br>\n", "4 check which tickers are still missing and manually complete them!<br>\n", "!!! Warning: Running this code in the future could produce errors if the information on the pages that we scrape <br>\n", "changes<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["Retreive Stoxx Europe 50 Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["page_StoxxEurope = pd.read_html(\"https://de.wikipedia.org/wiki/STOXX_Europe_50\")\n", "StoxxEurope_table = page_StoxxEurope[4][[\"Name\"]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Retrieve Estoxx 50 Data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["page_Estoxx = pd.read_html('https://en.wikipedia.org/wiki/EURO_STOXX_50')\n", "Estoxx_table = page_Estoxx[3]\n", "tickers_Estoxx = Estoxx_table[[\"Ticker\", \"Name\"]]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["complete missing tickers manually"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["temp = StoxxEurope_table.merge(Estoxx_table[[\"Ticker\", \"Name\"]], on=\"Name\", how=\"left\")\n", "missing_names = temp[temp[\"Ticker\"].isna()].Name\n", "missing_names = missing_names.to_list()\n", "missing_tickers = [\"ABBN.SW\", \"ASML.AS\", \"AZN.L\", \"BHP.L\", \"BP.L\",\n", "                   \"BATS.L\", \"MBG.DE\", \"DGE.L\", \"GSK.L\", \"HSBA.L\", \"LOR.F\", \"LIN.DE\",\n", "                   \"MOH.F\", \"NG.L\", \"NESN.SW\", \"NOVN.SW\", \"NOVO-B.CO\", \"PRU.L\", \"RKT.L\",\n", "                   \"REL.L\", \"RIO.L\", \"ROG.SW\", \"SHEL.L\", \"UBSG.SW\", \"ULVR.L\",\n", "                   \"DG.PA\", \"VOD.L\", \"ZURN.SW\"]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["missing_df = {\"Name\": missing_names, \"Ticker\": missing_tickers}\n", "missing_df = pd.DataFrame(missing_df)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["assemble final data frame which contains names and tickers of all stoxx europe 50 index members"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["all_tickers = tickers_Estoxx.append(missing_df)\n", "Tickers_StoxxEurope = StoxxEurope_table.merge(all_tickers, on=\"Name\", how=\"left\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Stock_Tickers = Tickers_StoxxEurope.Ticker.to_list()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##########################################################################<br>\n", "retrive financial ratios and calculate one year dividend yield as of end-backtesting date for all index tickers<br>\n", "##########################################################################"]}, {"cell_type": "markdown", "metadata": {}, "source": ["initilize empty lists to store results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ticker_list = []\n", "div_yield_list = []\n", "currency_list = []\n", "sector_list = []\n", "pb_list = []\n", "forward_pe_list = []\n", "trailing_pe_list = []\n", "country_list = []\n", "dividend_dict = {}"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "unfortunately accessing yfinance via api (yfinance package) does not always<br>\n", "return dividends or ratio information even if they exist.<br>\n", "Thus, for ratios and dividends we rely on yahoo_fin module which is much more reliable.<br>\n", "However, since it scrapes the data directly from the website and yahoo has very strict<br>\n", "rate limits, we pause the loop for a random time(between 100 & 200 seconds) after the website returns that we cannot<br>\n", "fetch any more data.<br>\n", "We notice that we are blocked by the website if: <br>\n", "dividend data frame comes back empty --> indexerror is raised by loop <br>\n", "ratios data frame with nan is produced for ratios -> We manually raise an index error to indicate<br>\n", "that the rate limit has been reached<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "!!! Warning: <br>\n", "This loop can take quite a long time to complete!<br>\n", "If you wish to skip this step, please continue below and just import the results <br>\n", "of this loop as a csv<br>\n", "- Also, the ratios which we download (eg. PB / PE ratios are the ratios from the day the script is run. Therefore <br>\n", "running the script at different times could produce slightly different results as unfortunately, we were <br>\n", "only able to get the most recent ratios and not the ratios per a specific date.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["i = 0\n", "while i in range(len(Stock_Tickers)):\n", "    try:\n", "        ticker = yf.Ticker(Stock_Tickers[i])\n", "        info = ticker.info\n", "        dividends = get_dividends(Stock_Tickers[i])\n", "        if dividends.empty:\n", "            div_yield = 0\n", "        else:\n", "            # calculate dividend yield as of 31. December 2021\n", "            dividends = dividends.drop(\"ticker\", axis=1)\n", "            dividends_year = dividends.iloc[(dividends.index >= start_dividends) & (dividends.index < end_dividends)]\n", "            dividends_year = dividends_year.sum()\n", "            price = ticker.history(start=end_backtesting - 10, end=end_backtesting)\n", "            price = price.Close\n", "            price = price[-1]\n", "            div_yield = (dividends_year / price)[0]\n", "        dividend_dict[Stock_Tickers[i]] = dividends\n\n", "        # get ratios\n", "        ratios = get_stats_valuation(Stock_Tickers[i])\n", "        ratios = ratios.rename(columns={0: \"ratio\", 1: \"value\"})\n", "        ratios.index = ratios.ratio\n", "        ratios = ratios.drop(\"ratio\", axis=1)\n\n", "        # if limit is reached, yahoo returns all NA's for ratios...\n", "        if ratios.value.isnull().all():\n", "            raise IndexError\n\n", "        # store raios and informational values in respective lists\n", "        currency_list.append(info.get(\"currency\"))\n", "        sector_list.append(info.get(\"sector\"))\n", "        pb_list.append(ratios.loc[ratios.index == \"Price/Book (mrq)\"].value[0])\n", "        forward_pe_list.append(ratios.loc[ratios.index == \"Forward P/E\"].value[0])\n", "        trailing_pe_list.append(ratios.loc[ratios.index == \"Trailing P/E\"].value[0])\n", "        country_list.append(info.get(\"country\"))\n", "        div_yield_list.append(div_yield)\n\n", "        # print progress of loop\n", "        print(\"import of \" + Stock_Tickers[i] + \" successful\")\n", "        i = i + 1\n", "        time.sleep(random.randint(3, 15))\n\n", "    # loop is paused after rate limit has been reached\n", "    except IndexError:\n", "        pause = random.randint(100, 200)\n", "        print(\"pause for \" + str(pause) + \" seconds\")\n", "        time.sleep(pause)\n", "        continue"]}, {"cell_type": "markdown", "metadata": {}, "source": ["assemble as data.frame"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks = pd.DataFrame({\"Name\": list(Tickers_StoxxEurope[\"Name\"]), \"Currency\": currency_list, \"Country\": country_list,\n", "                       \"Sector\": sector_list, \"Yield\": div_yield_list, \"Forward_PE\": forward_pe_list,\n", "                       \"Trailing_PE\": trailing_pe_list, \"PB_Ratio\": pb_list},\n", "                      index=Stock_Tickers)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "#to compare our strategy with that of the index, we also manually add the weights<br>\n", "as found on the ishares website to it (per 31. December 2021). <br>\n", "4 index members have been replaced since and thus there is a difference between the ishares data<br>\n", "and our index constituents (Vodafone, Safran, National Grid, BHP)<br>\n", "for each, the weight of its replacement is taken. The Impact of this is expected to be very minor as <br>\n", "all weights are < 2%<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks_indexweights = np.array([1.19, 0.99, 1.36, 1.52, 1.37, 1.77, 0.99, 6.12,\n", "                                3.35, 1.13, 1.19, 0.96, 1.16, 1.47, 1.63, 1.44, 1.18, 1.18, 2.34,\n", "                                1.14, 2.02, 2.31, 1.27, 0.87, 1.08, 2.12, 3.27, 4.01, 1.1, 7.25, 3.95, 3.43, 1.34, 0.87,\n", "                                1.16,\n", "                                1.19, 1.31, 5.38, 1.66, 2, 2.12, 2.85, 2.06, 2.4, 2.46,\n", "                                1.14, 2.59, 1.16, 0.8, 1.22]) / 100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks[\"index_weights\"] = stocks_indexweights"]}, {"cell_type": "markdown", "metadata": {}, "source": ["write data to CSV"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stocks.to_csv(\"files/index_constituents_data.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "If you chose not to run the loop above, run the below code to continue<br>\n", "--> CODE: stocks = pd.read_csv(\"files/index_constituents_data.csv)<br>\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["##########################################################################<br>\n", "Download Prices of Benchmark constituents and Exchange Rates to convert all Prices to EUR<br>\n", "##########################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Net_Price = yf.download(tickers=list(stocks.index), start=start_backtesting, end=end_out_sample, interval=\"1d\")\n", "Net_Price = Net_Price[\"Adj Close\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["get unique currencies of stocks"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["currencies = stocks.Currency.unique()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["download exchange rates against EUR of all currencies which are represented in the index"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["e_rates = yf.download(tickers=[\"CHFEUR=X\", \"DKKEUR=X\", \"GBPEUR=X\"], start=start_backtesting, end=end_out_sample,\n", "                      interval=\"1d\")\n", "e_rates = e_rates[\"Adj Close\"]\n", "e_rates = e_rates.rename(columns={\"CHFEUR=X\": \"CHF\", \"DKKEUR=X\": \"DKK\", \"GBPEUR=X\": \"GBP\"})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["fill values where we do not have data with previous value or delete if it is the first value"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Net_Price = pd.DataFrame(Net_Price).fillna(method=\"ffill\")\n", "Net_Price = Net_Price.fillna(0)\n", "Net_Price = Net_Price.loc[np.all(Net_Price != 0, axis=1)]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["##########################################################################<br>\n", "Calculate Gross Stock Prices<br>\n", "##########################################################################"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Gross_Price = pd.DataFrame()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["calculate gross returns based on assumption that each dividend is immediately reinvested in the given stock"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in Net_Price.columns:\n", "    temp = pd.DataFrame(Net_Price[i])\n", "    # handle stocks for which no entry in dividend_dict exists\n", "    try:\n", "        temp = temp.join(dividend_dict.get(i))\n", "        temp[\"share_purchased\"] = temp.dividend / temp[i]\n", "        temp.share_purchased = temp.share_purchased.fillna(0)\n", "        temp.share_purchased = temp.share_purchased.cumsum()\n", "        temp.share_purchased = temp.share_purchased + 1\n", "        temp = temp[i] * temp.share_purchased\n", "    except AttributeError:\n", "        pass\n", "    Gross_Price[i] = temp"]}, {"cell_type": "markdown", "metadata": {}, "source": ["export gross prices in local currency as csv"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Gross_Price.to_csv(\"files/Gross_Prices_localccy.csv\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["convert all prices to EUR! (gross and net)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["adj_prices_gross = Gross_Price.join(e_rates)\n", "adj_prices_net = Net_Price.join(e_rates)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i in currencies:\n", "    tickers = stocks.index[stocks.Currency == i]\n\n", "    # for stocks quoted in pence (100th of a Pound)\n", "    if i == \"GBp\":\n", "        adj_prices_gross[tickers] = adj_prices_gross[tickers].multiply((adj_prices_gross[\"GBP\"] / 100), axis=0)\n", "        adj_prices_net[tickers] = adj_prices_net[tickers].multiply((adj_prices_net[\"GBP\"] / 100), axis=0)\n", "    elif i == \"EUR\":\n", "        pass\n", "    else:\n", "        adj_prices_gross[tickers] = adj_prices_gross[tickers].multiply(adj_prices_gross[i], axis=0)\n", "        adj_prices_net[tickers] = adj_prices_net[tickers].multiply(adj_prices_net[i], axis=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["delete exchange rates again"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["adj_prices_net = adj_prices_net[Gross_Price.columns]\n", "adj_prices_gross = adj_prices_gross[Gross_Price.columns]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["write to csv files"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["adj_prices_net.to_csv(\"files/Net_Prices_EUR.csv\")\n", "adj_prices_gross.to_csv(\"files/Gross_Prices_EUR.csv\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}