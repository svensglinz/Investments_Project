{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "from yahoo_fin.stock_info import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#-----------------------------------------------------------------------\n",
    "#define parameters of investment period start\n",
    "\n",
    "start_backtesting = np.datetime64(\"2011-01-01\")\n",
    "end_backtesting = np.datetime64(\"2021-12-31\")\n",
    "\n",
    "#define end backtesting - one year as interval to calculate one year dividend yield\n",
    "end_dividends = np.datetime64(\"2021-12-31\")\n",
    "start_dividends = end_dividends - np.timedelta64(365,'D')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#ishares ETF on Stoxx Europe 50 used as benchmark (ETF is distributing --> paid out dividends were downloaded\n",
    "#separately and are stored in file \"dividends_benchmark.csv\" which is needed to calculate gross returns\n",
    "#with reinvested dividends)\n",
    "\n",
    "benchmark = yf.download(tickers = \"EUNA.AS\", interval = \"1d\", start = start_backtesting, end = dt.date.today())\n",
    "benchmark_dividends = pd.read_csv(\"dividends_benchmark.csv\")\n",
    "benchmark_dividends.index = pd.to_datetime(benchmark_dividends.Date, format = \"%d.%m.%Y\")\n",
    "benchmark_dividends = benchmark_dividends.drop(\"Date\", axis = 1)\n",
    "\n",
    "benchmark_net = pd.DataFrame(benchmark[\"Adj Close\"])\n",
    "\n",
    "#calculate gross index with immediate reinvesting of all dividends\n",
    "benchmark_gross = benchmark_net.join(benchmark_dividends)\n",
    "benchmark_gross[\"share_purchased\"] = benchmark_gross.Dividend/ benchmark_gross[\"Adj Close\"]\n",
    "benchmark_gross.share_purchased = benchmark_gross.share_purchased.fillna(0)\n",
    "benchmark_gross.share_purchased = benchmark_gross.share_purchased.cumsum()\n",
    "benchmark_gross.share_purchased = benchmark_gross.share_purchased + 1\n",
    "benchmark_gross = benchmark_gross[\"Adj Close\"] * benchmark_gross.share_purchased\n",
    "\n",
    "benchmark_gross = pd.DataFrame({\"Adj Close\": benchmark_gross})\n",
    "\n",
    "#write CSV for replicability\n",
    "benchmark = pd.DataFrame({\"benchmark_gross\": benchmark_gross[\"Adj Close\"], \"benchmark_net\": benchmark_net[\"Adj Close\"]},\n",
    "                         index = benchmark_net.index)\n",
    "\n",
    "benchmark.to_csv(\"benchmark.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Retreive Stoxx Europe 50 Data\n",
    "page_StoxxEurope = pd.read_html(\"https://de.wikipedia.org/wiki/STOXX_Europe_50\")\n",
    "StoxxEurope_table = page_StoxxEurope[4][[\"Name\"]]\n",
    "\n",
    "#Retrieve Estoxx 50 Data\n",
    "page_Estoxx = pd.read_html('https://en.wikipedia.org/wiki/EURO_STOXX_50')\n",
    "Estoxx_table = page_Estoxx[3]\n",
    "tickers_Estoxx = Estoxx_table[[\"Ticker\", \"Name\"]]\n",
    "\n",
    "#complete missing tickers manually\n",
    "temp = StoxxEurope_table.merge(Estoxx_table[[\"Ticker\", \"Name\"]], on = \"Name\", how = \"left\")\n",
    "missing_names = temp[temp[\"Ticker\"].isna()].Name\n",
    "missing_names = missing_names.to_list()\n",
    "missing_tickers = [\"ABBN.SW\", \"ASML.AS\", \"AZN.L\", \"BHP.L\", \"BP.L\",\n",
    "          \"BATS.L\", \"MBG.DE\", \"DGE.L\", \"GSK.L\", \"HSBA.L\", \"LOR.F\", \"LIN.DE\",\n",
    "          \"MOH.F\", \"NG.L\", \"NESN.SW\", \"NOVN.SW\", \"NOVO-B.CO\", \"PRU.L\", \"RKT.L\",\n",
    "          \"REL.L\", \"RIO.L\", \"ROG.SW\", \"SHEL.L\", \"UBSG.SW\", \"ULVR.L\",\n",
    "          \"DG.PA\", \"VOD.L\", \"ZURN.SW\"]\n",
    "\n",
    "missing_df = {\"Name\": missing_names, \"Ticker\": missing_tickers}\n",
    "missing_df = pd.DataFrame(missing_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4152/2939455302.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_tickers = tickers_Estoxx.append(missing_df)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#assemble final data frame which contains names and tickers of all stoxx europe 50 index members\n",
    "all_tickers = tickers_Estoxx.append(missing_df)\n",
    "Tickers_StoxxEurope = StoxxEurope_table.merge(all_tickers, on = \"Name\", how = \"left\")\n",
    "\n",
    "Stock_Tickers = Tickers_StoxxEurope.Ticker.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initilize empty lists to store results\n",
    "ticker_list = []\n",
    "div_yield_list = []\n",
    "currency_list = []\n",
    "sector_list = []\n",
    "pb_list = []\n",
    "forward_pe_list = []\n",
    "trailing_pe_list = []\n",
    "country_list = []\n",
    "payoutratio_list = []\n",
    "dividend_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import of ABBN.SW successful\n",
      "import of ADS.DE successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "while i in range(len(Stock_Tickers)):\n",
    "\n",
    "    try:\n",
    "        ticker = yf.Ticker(Stock_Tickers[i])\n",
    "        info = ticker.info\n",
    "        dividends = get_dividends(Stock_Tickers[i])\n",
    "\n",
    "        if dividends.empty == True:\n",
    "            pass\n",
    "        else:\n",
    "            dividends = dividends.drop(\"ticker\", axis = 1)\n",
    "\n",
    "        dividend_dict[Stock_Tickers[i]] = dividends\n",
    "\n",
    "        ratios = get_stats_valuation(Stock_Tickers[i])\n",
    "        ratios = ratios.rename(columns = {0: \"ratio\", 1: \"value\"})\n",
    "        ratios.index = ratios.ratio\n",
    "        ratios = ratios.drop(\"ratio\", axis = 1)\n",
    "\n",
    "        #if limit is reached, yahoo returns all NA's for ratios...\n",
    "        if ratios.value.isnull().all():\n",
    "            raise IndexError\n",
    "\n",
    "        #calculate dividend yield as of 31. December 2021\n",
    "        dividends_year = dividends.iloc[(dividends.index >= start_dividends) & (dividends.index < end_dividends)]\n",
    "        dividends_year = dividends_year.sum()\n",
    "        price = ticker.history(start = end_backtesting-10, end = end_backtesting)\n",
    "        price = price.Close\n",
    "        price = price[-1]\n",
    "        div_yield = dividends_year / price\n",
    "\n",
    "        #store values in respective lists\n",
    "        currency_list.append(info.get(\"currency\"))\n",
    "        sector_list.append(info.get(\"sector\"))\n",
    "        pb_list.append(ratios.loc[ratios.index == \"Price/Book (mrq)\"].value[0])\n",
    "        forward_pe_list.append(ratios.loc[ratios.index == \"Forward P/E\"].value[0])\n",
    "        trailing_pe_list.append(ratios.loc[ratios.index == \"Trailing P/E\"].value[0])\n",
    "        country_list.append(info.get(\"country\"))\n",
    "        div_yield_list.append(div_yield[0])\n",
    "\n",
    "        #print progress of loop\n",
    "        print(\"import of \" + Stock_Tickers[i] + \" successful\")\n",
    "        i = i + 1\n",
    "\n",
    "    #loop is paused after rate limit has been reached\n",
    "    except IndexError:\n",
    "        time.sleep(100)\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#assemble as data.frame\n",
    "stocks = pd.DataFrame({\"Name\": list(Tickers_StoxxEurope[\"Name\"]), \"Currency\": currency_list, \"Country\": country_list,\n",
    "                       \"Sector\": sector_list, \"Yield\": div_yield_list, \"Forward_PE\": forward_pe_list,\n",
    "                       \"Trailing_PE\": trailing_pe_list, \"PB_Ratio\": pb_list},\n",
    "                       index = Stock_Tickers)\n",
    "\n",
    "stocks = pd.read_csv(\"index_constituents_data.csv\", index_col= 0)\n",
    "\n",
    "\n",
    "#to compare our strategy with that of the index, we also manually add the weights\n",
    "#as found on ishares to it. #4 members have been replaced since (\n",
    "#Vodafone, Safran, National Grid, BHP, for each the residual weight / 4 = 1.2% is added)\n",
    "stocks_indexweights = np.array([0.97, 0.68, 0.93, 1.68, 1.37, 1.76, 1, 4.49, 4.24, 1.05, 0.99, 1.38,\n",
    "                       1.2, 1.35, 2.12, 1.89, 1.17, 1.4, 2.17, 1.05, 2.34, 2.63,\n",
    "                       1.44, 0.8, 0.72, 1.64, 3.31, 3.24, 1.2, 6.83, 4.52, 3.75, 0.87, 0.72,\n",
    "                       1.2, 1.17, 1.52, 4.81, 4.63, 1.2, 2.58, 2.22,1.58, 1.9, 2.98, 1.25,\n",
    "                       2.41, 1.19, 1.2, 1.39]) / 100\n",
    "\n",
    "stocks[\"index_weights\"] = stocks_indexweights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#write data to CSV\n",
    "stocks.to_csv(\"index_constituents_data.csv\")\n",
    "\n",
    "#Download Prices of Benchmark constituents and Exchange Rates to convert all Prices to EUR\n",
    "#-----------------------------------------------------------------------------------------\n",
    "\n",
    "Net_Price = yf.download(tickers = list(stocks.index), start = start_backtesting, end = dt.date.today(), interval = \"1d\")\n",
    "Net_Price = Net_Price[\"Adj Close\"]\n",
    "\n",
    "#get unique currencies of stocks\n",
    "currencies = stocks.Currency.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#download exchange rates against eur of all currencies which are represented in the index\n",
    "e_rates = yf.download(tickers = [\"CHFEUR=X\", \"DKKEUR=X\", \"GBPEUR=X\"], start = start_backtesting, end = dt.date.today(), interval = \"1d\")\n",
    "e_rates = e_rates[\"Adj Close\"]\n",
    "e_rates = e_rates.rename(columns= {\"CHFEUR=X\": \"CHF\", \"DKKEUR=X\": \"DKK\", \"GBPEUR=X\": \"GBP\"})\n",
    "\n",
    "#delete values where we do not have values for each trading day! (or fill with last available value)\n",
    "Net_Price = Net_Price.fillna(0)\n",
    "Net_Price = pd.DataFrame(Net_Price).fillna(method = \"ffill\")\n",
    "Net_Price = Net_Price.loc[np.all(Net_Price != 0, axis = 1)]\n",
    "\n",
    "Gross_Price = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculate gross returns based on assumption that each dividend is immediately reinvested in the given stock\n",
    "for i in Net_Price.columns:\n",
    "\n",
    "    temp = pd.DataFrame(Net_Price[i])\n",
    "    #handle stocks for which no entry in dividend_dict exists\n",
    "    try:\n",
    "        temp = temp.join(dividend_dict.get(i))\n",
    "        temp[\"share_purchased\"] = temp.dividend / temp[i]\n",
    "        temp.share_purchased = temp.share_purchased.fillna(0)\n",
    "        temp.share_purchased = temp.share_purchased.cumsum()\n",
    "        temp.share_purchased = temp.share_purchased + 1\n",
    "        temp = temp[i] * temp.share_purchased\n",
    "\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    Gross_Price[i] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert all prices to EUR!!! (gross and net)\n",
    "adj_prices_gross = Gross_Price.join(e_rates)\n",
    "adj_prices_net = Net_Price.join(e_rates)\n",
    "\n",
    "for i in currencies:\n",
    "    tickers = stocks.index[stocks.Currency == i]\n",
    "\n",
    "    #for stocks quoted in pence (100th of a Pound)\n",
    "    if i == \"GBp\":\n",
    "        adj_prices_gross[tickers] = adj_prices_gross[tickers].div(adj_prices_gross[\"GBP\"] * 100, axis = 0)\n",
    "        adj_prices_net[tickers] = adj_prices_net[tickers].div(adj_prices_net[\"GBP\"] * 100, axis=0)\n",
    "    elif i == \"EUR\":\n",
    "        pass\n",
    "    else:\n",
    "        adj_prices_gross[tickers] = adj_prices_gross[tickers].div(adj_prices_gross[i], axis = 0)\n",
    "        adj_prices_net[tickers] = adj_prices_net[tickers].div(adj_prices_net[i], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#delete exchange rates again\n",
    "adj_prices_net = adj_prices_net[Gross_Price.columns]\n",
    "adj_prices_gross = adj_prices_gross[Gross_Price.columns]\n",
    "\n",
    "#write to csv files\n",
    "adj_prices_net.to_csv(\"Net_Prices_EUR.csv\")\n",
    "adj_prices_gross.to_csv(\"Gross_Prices_EUR.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db772567c4567f4b3d1f56ed53e5d7229d15382f6d3dfec57e0c55f7b5cf2dd9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
